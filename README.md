## JusticeBot: A Virtual Legal Assistant
The JusticeBot is an innovative Retrieval-Augmented Generation (RAG) based chatbot designed to revolutionize legal information access on Justice Department. Leveraging advanced language models and cutting-edge AI technologies, the JusticeBot facilitates immediate, accurate, and user-friendly guidance across various legal and judicial services. It streamlines complex procedures by providing detailed explanations and step-by-step instructions, ensuring users can efficiently navigate their legal needs.

## About
JusticeBot, a Retrieval-Augmented Generation (RAG) based chatbot, is designed to enhance user experience by offering instant access to various eCourt services, including case searches, hearing schedules, court orders, and payment processes for fines. It further simplifies access to citizen services by delivering clear and concise guidance on legal aid, petition filing, and traffic violation settlements. Additionally, the chatbot promotes transparency in the judicial system by facilitating the live streaming of court cases, while ensuring 24/7 availability of crucial legal information.
Utilizing ChromaDB for efficient data management and data retrieval and AWS infrastructure for scalable and cost-effective deployment, the JusticeBot is built for cost-efficiency and future expansion, with capabilities for Reinforcement Learning with Human Feedback (RLHF) and potential multilingual support. Despite challenges such as local LLM limitations and the complexity of processing large legal documents, the JusticeBot promises significant social, economic, and environmental benefits by promoting legal awareness, reducing operational costs, and minimizing paper usage, the JusticeBot empowers users, fostering confidence and equitable access to justice.

## Features
<!--List the features of the project as shown below-->
- Implements advance neural network method.
- A framework based application for deployment purpose.
- High scalability.
- Less time complexity.
- A specific scope of Chatbot response model, using json data format.

## Requirements
<!--List the requirements of the project as shown below-->
* Operating System: Requires a 64-bit OS (Windows 10 or Ubuntu) for compatibility with deep learning frameworks.
* Development Environment: Python 3.6 or later is necessary for coding the sign language detection system.
* Deep Learning Frameworks: TensorFlow for model training, MediaPipe for hand gesture recognition.
* Image Processing Libraries: OpenCV is essential for efficient image processing and real-time hand gesture recognition.
* Version Control: Implementation of Git for collaborative development and effective code management.
* IDE: Use of VSCode as the Integrated Development Environment for coding, debugging, and version control integration.
* Additional Dependencies: Includes scikit-learn, TensorFlow (versions 2.4.1), TensorFlow GPU, OpenCV, and Mediapipe for deep learning tasks.

## System Architecture
<!--Embed the system architecture diagram as shown below-->

![Screenshot 2023-11-25 133637](https://github.com/<<yourusername>>/Hand-Gesture-Recognition-System/assets/75235455/a60c11f3-0a11-47fb-ac89-755d5f45c995)


## Output

<!--Embed the Output picture at respective places as shown below as shown below-->
#### Output1 - Name of the output

![Screenshot 2023-11-25 134037](https://github.com/<<yourusername>>/Hand-Gesture-Recognition-System/assets/75235455/8c2b6b5c-5ed2-4ec4-b18e-5b6625402c16)

#### Output2 - Name of the output
![Screenshot 2023-11-25 134253](https://github.com/<<yourusername>>/Hand-Gesture-Recognition-System/assets/75235455/5e05c981-05ca-4aaa-aea2-d918dcf25cb7)

Detection Accuracy: 96.7%
Note: These metrics can be customized based on your actual performance evaluations.


## Results and Impact
<!--Give the results and impact as shown below-->
The Sign Language Detection System enhances accessibility for individuals with hearing and speech impairments, providing a valuable tool for inclusive communication. The project's integration of computer vision and deep learning showcases its potential for intuitive and interactive human-computer interaction.

This project serves as a foundation for future developments in assistive technologies and contributes to creating a more inclusive and accessible digital environment.

## Articles published / References
1. Lakshmi Priya Grlamudiveti and Dr. Sagee Geetha Sethu, “ROLE OF ARTIFICIAL INTELLIGENCE IN THE INDIAN JUDICIAL SYSTEM” in 2023 international conference on computational intelligence and knowledge economy (iccike), march 9-10, 2023, amity university Dubai, UAE

2. Gulimila Aini, “A SUMMARY OF THE RESEARCH ON THE JUDICIAL APPLICATION OF ARTIFICIAL INTELLIGENCE”, 2020 - Beijing normal university law school, Beijing, China

3. Dr. Hemlata Sharma, Aakanksha, “ARTIFICIAL INTELLIGENCE AND LAW: AN EFFECTIVE AND EFFICIENT INSTRUMENT” in 2021 9th international conference on reliability, infocom technologies and optimization (trends and future directions) (icrito) amity university, Noida, India. Sep 3-4, 2021




